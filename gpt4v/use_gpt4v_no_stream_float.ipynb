{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/742 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 742/742 [00:00<00:00, 1819.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['VlLHMWFVgvk', '0_8zVtd5VLY', '_LzlQLGcAnc', 'FJF56lmDqQo', 'kVh1Jw2D9NY', 'tz56LhvDFho', '4HN0caXjW3s', '9n23ISvkbFQ', 'xQ9lcCGI6Qk', '0S5i79_1t8k', 'AQX2Q-V2Uh8', 'BEOdicifuqM', 'fmuEMg2fh_8', 'FbTXTUnwCAE', 'EvpwbdkhdnA', 'UjH9kYibsAs', 'TZQWu0gDpO4', 'N-6zVmVuTs0', 'NRTiivjQ2g0', '2qLtqZOlSEg', 'NFKdaj1Qsek', 'KD7l7XgWSXs', 'wA4i3eHKsTQ', 'epy3Dy2FUOI', '7a9g6mvCGWU', '2XFVnzr4Vho', 'eZHlWaIYjNE', 'ogIbkhMeJFI', 'ZyIQkgixS_o', 'jiMUoVjQ5uI', '_0at8kXKWSw', 'N3QuD26DuCI', 'DB7de4nC2rc', 'fFan929BTPE', 'nxt9PPJk2vs', 'QRRzvOvG21E', '5ctQIheACWk', 'o6hMDs4rBmw', 'EeClqsYITso', 'C0g5RjQ7cRE', '4dVIxwhMYL8', '7oi9IQwXhHQ', 'Lv41GcKWfJg', '90P3VEbzUK0', 'kzhJb5jcH58', 'OLw7cIJApMI', '2p3El_mx-J4', '3BzCHc25Row', 'P9372fjJKqo', 'TewPhK6CZ-Q', 'HJaWyfFQbEU', '0USGkmweHJM', '5RS1CKa3JVg', '66ojfophGys', 'TCCYCSACA2Y', 'DBzEhaJmBYY', '6kYu7-5EyU8', '_NQec_YluKU', 'h7YTPuEMgaE', '8xFtIsyRvNE', 'PBVW7az0PkM', 'uivjORoSW0k', 'WR0hwJp9AOA', 'nvdBfpA8r4o', 'luJceOt47UM', 'wbIH6b62y0g', 'oRBPxefAHTY', 'AqKpGR4EocU', 'urYGhhMOToU', 'Amq4kBfbqL8', 'vqFmKLl2hq4', 'CdUTSyU8LCo', 'J1oI2CHFgPU', 'pMU2Pk-SBs0', 'reIyMTBfEwQ', '6omsUi4dKuk', 'COYJC6dvB8I', 'mdgbtrpVBm8', 'y5rf-o_w-Ds', 'p3qZtbpwrB8', 'xs8O-MFu4yU', 'KHgGasfOFPg', 'XP71dJlnLJQ', 'VIVkYG31Oas', 'hrhX40bQYY0', 'lawcIailzXE', 'IXbAYg5pp9M', 'jtl1GY2TF7A', 'bMuoPr5-Yt4', 'HEMqddRGVBY', 'sheEL099ADM', 'k10DDJ4L2lc', 'E0TBOKN8J2E', 'WdhVIZuKHo0', 'E2IdU5lgaH4', 'E_YpGd40wJU', 'SSk0B0dVq4g', 'He00-agbGRc', 'Bd_vAawM9LA', 'CXmRmrBPDII', 'J5TLIOf5uDo', '65NCcXriUTI', 'nyTDC1m5MFM', 'fz0q7YKjp48', 'XtW6mNBM9ro', 'Y7eYfHIyn3M', 'O_xHNbx5jqI', 'o7Ax6SRTGks', '8Nbr0lYFLew', '2Vam2a4r9vo', 'fce2RtEvPr8', '0AslM2bC5DY', 'e6ppqFNBkLo', 'Csy2RxzkbaM', 'mpHoYhIFKNI', 'sYRbtseSdy0', 'y1Y02_oZP8U', '4VA4kqMnEqA', 'BH8FUBW4IIE', 'JF1RDNUTsJw', 'Mf76yyTY7Ss', '2YGrrsKs-Xg', 'K-bZQJ3P9N0', 'QUd09jZIQEk', 'CkhgusyxPDU', 'vE0R-Gw_GEA', 'm7IgZco6brk', 'fsBzpr4k3rY', 'I4mItsGR3uI', 'dZPwXsbohK4', 'OWXlfOnU6tc', 'e6zn4UlO0fU', 'RZzaa_PqNJI', 'cq1er8IWz1U', '5G4rOEjfxZQ', 'jYSuKn09_e4', 'J94uO-urSTg', '_71jULUUQhg', '0hCihQ5Kep0', 'k4X42D5Gg7o', 'bgczomH1kLk', 'DZsBei4nCkU', 'pesYeCruSyI', 'q-1DREuXwjc', '0KoG04_heLE', 'ON45DvDMSk4', 'WXuRTQPKwqY', 'tOcnYAE2i4Q', 'jbHKeVsI35M', 'u484hWA0imw', 'oMnt3bHBW30', 'zJ08DhVEAiI', 'iNPwOO_Minc', '5bBEsyEGVDs', 'DelU5tQ4grw', 'OMkfujDPpwc', 'j4OMpEp-bFk', 'Ob3hr2H3VD4', 'MB5zQ9X-2tY', 'Vwn_QS9vB1g', 'LuLPvA-QPq4', 'ICBNX0i855Q', 'nuZ-TPF_HIY', '4_BudcPRi7E', 'HwIRCeUCyxw', 'e4mvg9r6_cI', '8w41NfRyWqE', 'qN-ZCqaSHHk', 'BzEjGy7EPIc', 'jbN9n-cClPg', '0A0kEeMHVYI', 'bwyDxzs6D2g', 'muuW2EU8nrA', 'gN4FSWCPFW4', 'NHy5ma4NBK8', '0XPNvEJ0Xx4', 'LlenjGY2GqE', '9m0d0RaWpfY', '4AmVjblOvy4', 'bJK9E08dNpE', 'QQKG6cd-sBI', 'DuXGDE6tolY', 'A8Tw5xASluI', 'i3Y6m73J-uk', 'q3FHCB6X0v0', 'VPoNcAeOycw', '_AuZO31q62g', '3B_rRmkbA9I', 'QK1Xnd7cPJw', 'tXG-qPZJj-8', 'YlVkBzXo0YM', 'PlKDQqKh03Y', 'jZO9d1Gijv8', 'zzERcgFrTrA', 'SJSmbF9W9PQ', 'NqCeCRNC1qs', 'JhSRGLe18OI', 'CNHBsxOZd80', '9kLNVTm3Z90', 'kxZQeR3c_Wg', 'gK2GPxtCaGU', 'qkq9k5FewvI', 'jfKDozXX_Uo', 'R5409gLbXuw', '34XCuNsQ7O8', 'XYviM5xevC8', '0VfHifH5IQQ', 'wXQ1EhVW2xQ', 'mgfVV8B5J0M', 'JuFTJimHjoc', '29rvfxBQBQA', 'ctZDjBnEFBM', 'Ha_7S78KExo', 'tv-hgegVq0k', 'JC2eKssXavo', 'bvZ2lk-qzPo', 'OT3MVRv0TT4', 'KvbeKlGeNRU', 't-dmFuH7TyM', '1hyzWfYu6J0', '0X0H70JBnBM', 'WCM5kknf5nI', '43fC9xuQRCY', 'waE2GdoBW68', 'abOuBvUfQk4', 'wu9D9hdwOQ8', 'K6bTibRdNxE', 'royuCXeS8go', 'wxhUTK7xbz8', '_tBXwqueWcg', 'Wg7ppxAgcuw', '7doQf8xjFVg', 'L3VrqUxGVc4', 'kl3DqK3BGHI', 'SrMN3rwvCsE', 'JUGSh3BMuaQ', 'tfVvLs379Oo', 'T1icdxz0TNs', 'noHN3H3gWPQ', 'YI5l5ltMl8g', 'LVm_DbyklO0', 'qc1k6uf-Mbg', '6rkV4QRcVnk', 'df2QdWqKC6Q', 'xITR-FIi_oA', '9jRkACywckE', '7IwkRaz7uNs', 'oxZYBldwpP4', 'rAGZLKO6LR4', '6I7Ktp4dV_s', '0o5QeWZtgnY', 'XeSYqJ5WzTw', 'D6AzQTg_bPA', 'SQ8aRKG9660', 'RZPBl5-cu3c', 'wB_hjqZQ1UY', 'EC77tcJZIdU', 'nkUW8cR67Qw', 'HEke6Dlhqtw', 'FOWZ7B1QenY', '5XEQ8rYl1qs', '_v0aLo9ualA', '1GJqfyzfCWU', '8Kx0qYRv8XQ', 'TNVwN7IfVAw', 'sNcBUOlGBcg', 'Cj-H4ZcfVU8', '5h-SslT--8E', 'i7JGn06gsnA', 'PjBxYw4SJVg', 'JRYjFh_hHBs', 'geaSpx-R4Kc', 'RFcuAhpQdXU', 'f-BbAnnQVtY', 'fMxA90YU2Jw', 'rB6WmWvvyxg', 'Au_YiGhjXwg', '97AUfvzQ_1E', 'Q3JqdmUTsLI', 'iDgaqD7CWXU', 'fV1o_g6uzuI', 'mmCjPdu2TC4', 'pYCcwU9F_nc', 'UQsPI7lADiI', '8KI7JhLkezM', 'qQPl5ySv3Fk', '7hyT8HAb6ZU', 'TP4alkgoZis', 'lbZ979loVwE', 'ixQbCXLUUj8', 'K9aDdHC7_P4', 'bb08nFwfoxA', 'LD1RAPiT_7A', 'VITNLDx3Kgk', 'Fz9HnTVx52g', 'G3xzem7HSME', 'uk0Ntd8lJ98', 'Xs1sMqpc1oM', 'iwryTZf6bA0', 'BTx-iiFZhFE', 'jvpj4qdPRE0', '4yr_etbfZtQ', 'AHiA9hohKr8', 'OsQdzsIMFPQ', 'anokNvPMR5M', 'Vq2YQ_fXZoA', 'wHSH-NpCQOw', 'KWnV1Aa6VQ8', 'OKR7b6NL6IU', '1CjUHNYzW1E', 'HHqi6ZB_F0U', '2ZkzLAQszHA', 'alg7qHta0Sk', 'jtl5XK7QP38', 'lKqBsgfSSU8', 'MevYeKlyQM8', 'EWUfDU8TWn4', 'RUjbZ6Jymfg', 'mA402F5K47o', 'B5ltukfhtw8', '1Igt8Zl7xwM', 'B2V9PFGQBH4', 'DnvRlkLQ3Z4', 'CoMz3JOnZFo', 'DpTB4TDKIa0', 'RyObt_1eT8M', 'zLBEFvMkQCo', 'LmCJIBsQjOY', 'iNr9xdc6cVA', 'quEBzmchcwc', 'SN_U0Pc9YKU', 'Y9yrupye7B0', 'njq3H2iy2X0', 'pFUXcA1fp6g', 'XSYGzWuMxf8', 'ATxwkq1fkQQ', '3oj7mCSydoM', 'OrxsZHRGxRc', 'gA14LXQf-ZI', 'J6o_nljFyjg', 'kmi_liqBsdU', 'n5uadToINEY', 'aSZ_eLxuLAs', 'ctHj7R35dL0', 'AgLQ3qTL-t0', '8SGQ0VdXvAg', 'LtR1MukQIpY', 'sjzVFt59eds', 'Mh6PbpH9oPU', 'DLzp0YkZnRc', 'lKPRa_4hnlE', 'svZy-kdScDA', 'Obde542xA9I', 'LU1A0sHWYQg', 'ilotZqzaZgU', 'xpIFaKnNvco', '_33snCsG6nY', 'xXIq7YPkdUQ', 'XHtJKRfT7Ck', 'vTTzWRdAN4M', 'ieXrbTpZsvM', 'oZu2JfM2Aq8', 'xWLmbDdg9tY', 'sbskrTnC404', 'rFim4AcaAaU', 'Nra5F1tQQww', 'irJR5kZA_Ag', 'yczB2SXT5zs', 'dLAfUehM_6U', 'g7OMgsD7T74', 'f6-8wpMn_8I', 'gDVmHsYgJUA', 'kOIWYXDRR7s', 'pt7052eLUjg', 'YAYfMkxhRiQ', 'yjSQMZSEV4Y', 'E1I0hAxGFXw', 'Nba7GAP4E0k', 'G4RvOmNedls', 'ZLQfk-bDftQ', 'lickge5rPdc', '9yEQNadkc0M', 'b1OedrPQ464', 'afkL-ZyBsp8', 'PCVvpS7w-2w', '_xChA_vIuxE', '8xjAVkLT_0U', '_Z1tcdf6qkI', 'hd8bXHCvZME', 'QFTvmsHgFYM', '_r6i8Ae0cvo', 'AiIrjf-s128', 'shL1gWm9qdg', 'A_aFnxsStao', 'qr69jLeQdRA', '7GRTyxc4uMU', 'QoIsjc4-GIg', 'jA0RnDQiFbQ', 'H0Qdz8bSkv0', 'x883mrwYjDM', 'GMidefrr1MM', 'oG9xK1_yz4s', 'rMRWJEvKopk', '_T3uHSwRgdU', 'B2CEGhwMjkQ', 'R-xtt7w9Do4', 'qp-Jr4oEFWo', 'vLS1o1F6KqE', 'KPMSMXne3zw', 'uANIooMR9a0', 'TGbe5v-Pz2E', '0-HM2VCdrC0', 'VsSGubvfPiA', 'EwAb8ZW5Eiw', 'fHW461eiQp8', '9VVdihKALKU', 'pK1WAx4jJzE', 'xcyTsEewkyE', 'P3UP62l7g6Q', 'rbXEZz5idLo', 'mO8TK-QaIf8', 'pAoTHS4JSi4', 'a0RT3nSOCwU', '4Vic0qKl64Y', '1YFLBjR-swo', '5I8SQFfh73U', '_QNlEnY-xIg', 'f6Oo9vLtKtA', '2MrFWB__GIA', '9dmlcGZta9E', 'D1FXpqUivtU', 'YZR6LEk3doM', 'jxsvzuRl1O8', 'rbAZyZwvNiM', 'OgkMqPvKTQU', 'bCKOVlsSluU', 'caOaW604Tqc', 'Op2e8_JURSQ', 'b0yONlMjxjs', '56EbHWYK_q0', 'kRh1zXFKC_o', 'rq-7zoXQ69Y', 'bC9hc4cqHGY', 'bCWEOlvi5fY', 'eyvnq3CH5dg', 'vZAQjsoMbKY', 'Nx5VK6DUUEY', 'NmWjnYUkT_s', 'oY6BfHkNFPY', 'NcHQjL_WlxQ', 'ZbiGzK3slg0', 'XNxn_IuZ0bA', '4RBnTZELQX8', 'JW2HHfQiGVs', '326RvY72nmE', 'yPHYjeHk1YM', 'iwxe2sIgQL0', 'sZ9gSPUdZIA', 'ap9vRY_Vdwc', 'xSVasSOEG28', 'rj21NdUuK5w', 'EUIIWsgDpZY', 'bH9M51XJoWk', 'Va54WZgPTdY', '89yPHsT8AKg', 'Xgsp3TzXR_g', 'H8ToqWfFevw', 'Fi4ixdzoA7I', 'nZiIVvEJ8m0', 'OsZNCbjk-cc', 'IsgFVkMnqJc', 'PR04klFMPYQ', '4W192A7g5KY', 'd-zZYDU0qXY', 'wkqss9zZOhc', 'lTk5zkc0i8M', '0gqxDPO3I9g', 'W_CvL_fMIm4', 'LhSqS7rUdkA', '5hXXFQLDsoA', 'zqgqVF6lWB0', 'dKXaAlmLCCI', '8l7vdwu6B9s', '8DMkk6bFrUE', 'OWsT2rkqCk8', 'G4heS2754l4', '1B_swZA4Hqk', 'VbOjicIdrIE', 'gBs-CkxGXy8', 'oAnP5eU7IbY', 'Qp7epu5AtsQ', 'RHRPK2O9R4w', 'Jx5O2VW0pIw', 'Yzq6fNeXf6w', 'sqDIGuzt38w', 'm1psUANLFgA', 'GKNkucKoryE', 'VPTjROKYhlU', 'dU7L1hvMx9Y', 'ahcAFnY6iAY', '6qIBzPrHoVk', 'k-kyKv_kKGU', 'aqGNOsZFdBU', 'a7t6tQVX7T8', 'HFlPtsa7WV4', 'L3uDQ0S1Iis', 'kx-B4SYbglE', 'AQ7wbfX_av0', '7MF2IgjAjjA', 'QNWXsYZWiiA', 'KBMAUGQpHBU', 'iLLPJXaHosI', 'VP4rHzYyuL0', 'hL2u93brqiA', 'HMkOO15nye8', 'DWmUHNpOJxI', '1a4Gx6UHdI8', 'jJ9VFThsqtU', 'IlLFTI24Qkw', 'rFJIgAmT8dE', 'cvaUo282fEg', 'ax59TmvzCEg', 'ns3j2exbdbU', 'MIFz86h5nEA', 'c_9UEn3_z9Q', 'J3PZoq9gfvo', 'vajeoyUEuts', 'Ja2fgquYTCg', 'fZuk-TaECZo', 'isAi9mfPeEg', 'Hio3zTLWvSk', 'MHVrwCEWLPI', 'F2YbeTjcpfs', 'PQW7zw2URes', 'B1VB7vVQNQg', 'iIPeQxzLVlY', 'GGEXxniRfWQ', 'RsqRaVYQ6Cc', 'N188QSyfmeQ', 'cGU1Pepn1hU', 'G1wsCworwWk', 'jK08J1811uA', 'LdrTTX-GBCA', 'yuU67Mv4bFA', 'keth0g3CMK4', '8Kv4F0D210A', 'ZuBzOV1ADkk', 'omuQCh4rTT0', 'GXZSat3AqwE', 'TmPrJM8XTKA', 'KtEzZuRX23M', 'aP7X7XLbQx0', 'gjX78p5tvfo', 'BnkKxVNBDCA', 'ubH-d0KJUJE', 'VCJrgPb3y80', 'T0cNy3l6Zek', 'EqXKrS3gPN4', 'A48AJ_5nWsc', 'kztkcj-WAvw', 'psEglVHxbCA', 'MlteErDn4to', 'Crp5I6NXX8w', 'iAlU6xt7Y_s', '0GQ8pgQJShg', 'br0mu7r-ak0', 'KynPhJA4yww', 'NR9v3PBJw8g', 'hBdsfj0YPO8', 'XE1tSH1Ddt8', 'R_nAa-dNKSU', '7FYHA728nBI', '7bc_qfRmPK0', 'LoMhBo8ATBM', 'M4blAdS6r3Q', 'rc5v5EODszE', 'sJR9QjezRGg', 'ocg0MbBfCS0', 'yq1cX1lAyQg', 'pI6EUdTZOy4', 'DLVfYn9pvwo', '2hLcCnZzRtY', 'O8iOYngEUBU', 'bQzBPo2qRuk', '4qEJTg4Gc-g', 'n5_HdNzf03Q', 'RRlOGIWWKe8', 'Nck6BZga7TQ', 'otna1VHHCow', 'yDDRstyk9Dg', 'j_a_zvQOrIE', 'FSAcm6Kb7bk', '96YOZOU7ggo', 'SWNXZbasPvQ', 'ZP8ACbJ677I', 'TsT0ExNMK3I', 'ocqy8r8rDI0', 'i3itBKdwE7M', 'DlwuwiBLAmM', '6f2-XlVHGcc', '27-iN-FP-4s', 'Nv_M7NxzIYA', 'ory7fcHYXhQ', 'vwrWW26_JHY', 'Jp_KHLvQcuw', 'tbwPN9fZb2Q', 'LOxqK6o4NN0', 'q53HUAKB9oU', 'O0vFdR72In8', '6tAfdCTnToY', 'TyFWoohX0bo', 'HzvL4MonF-I', 'NgPP6UXVkYU', '1bh8HDoMP3Q', 'vaHpVjqCnNE', 'I0izJOlMJiM', '9LvdctnZeWE', 'fVtraC0jglE', 'vjZDdaFTubE', 'dzYHXvrsOWk', 'aUWOzyo-Kec', 'w62yEcbhgsc', 'jP2HuCwfKFA', 'dx1RPbGsjfk', 'SrqVUFbk_sE', 'Bzd07cbr3y8', 'a81pNygdAXw', '6MyobcYyKVk', '47mT0jC_aXA', '72ltfGTYqpQ', 'vuH6qsLU1j4', 'h9lNAmVKH4k', 'ZMJw752P7z8', 'jzhXtCHYrAM', 'QHeNKMxsqYE', 'hKfNp8NU82o', '8bY4qPadkSo', '8yX0E-XQcms', 'HFPGeaEPy9o', 'sqIR2N5izHo', 'vT73BECdSjQ', 'xNxw4rbwh68', 'VsBgMRrXiFE', 'Gsc0wN4FTdo', 'jf9ftrqWrwY', '_CuZqXrhEZI', 'WICJ9p79NMU', '3hcHRAFPBVY', '48aXQ4h-nK4', 'jsLUidiYm0w', '_tYPnaK5gkI', 'gbVOyKifrAo', 'W_GrHtwZez8', '7TDp3USwyww', 'tQW5JYgxCbk', '1Za8BtLgKv8', 'hF2vmguAs-I', '0a2lv4IwZFY', 'mGf4oL6RLGs', '3vjA8sDxDuQ', 'SlYEmc4yNYE', 'Ekl021fmWGc', 'Po_w8OmTfoY', 'Kjlt_FgKPgA', 'fSDmYGW8H7c', 'hezHSFSwa08', 'ooUw7Hq8YLg', 'ZCYbGGfwbfk', 'qRM1D4jE09w', 'tJhE0oC24FI', 'kYnmc_AVfMs', 'pMGhqE76kQA', 'SstGaYWCNoQ', '4wdeBJ39Cuw', 'mRU3zgkRp5w', 'TTY4WKXoPac', 'KHzSw7NrH7I', '_6qbppwnkq8', 'TA3Xy53hMMY', 'nblf7Yw4jys', 'tth90qiKXgY', 'O951zoCuU7Q', 'GARQJHyaBD0', 'T__twbwyFq0', 'teg6qTE9Hjs', 'Rv2hRfqlJaE', 'zzJM4vWqJvA', 'zzWaf1z9kgk', 'XNG8wW6Ffw4', 'x6YzIqb6Cas', 's5ak_9z3Cp8', 'VeV7vvfipA0', '5IzNXdsZUHk', 'v2tEGbTpIDU', '784nv_NRf4k', 'oW3UPfXHSUs', '8ACAI_Z7aLM', '3SGIHbvcTRc', 'O24d_rJ4uDo', 'A3WbCRfad-w', 'XYBx__4iAUw', '9GNlkpTJW9M', '9hn6Z1o-IYI', 'P2rLv-vjSOs', 'PsOnuG1EBjQ', '2yI50UZ9C4M', 'CuDdMyf639Q', '4tLBy9FGS5A', 'SUKdlcCiE60', '4LGe265pwvU', 'gWB-uAtqUIs', '3esHlM0cBx4', 'aRQLU3IwNYs', 'S8bqJTv_v1g', 'ah8Vjbs3JsM', 'YsBSR_z9BR8', 'RTpOZyd5qJo', 'ajfbq4d2EpY', 'oqKAuNefcSM', 'RFqPiA2NZhY', 'YVHJpAROBvQ', 'sILyPxN_1Dc', 'w_WAB7TXtXQ', 'gImYPbTTZko', 'geiub8WP_XE', 'o4CKGkaTn-A', 'gKuBUQVcDJM', 'MqiOBIxouw4', 'DMo2qyKq4_w', 'vSLOINP7w0s', 'd7Gzm3SnUaY', 'WBOT0Tqpbag', 'Ag5rCNF7P6o', 'q2EU-k9I5yg', '58DqoE56OWc', 'ArlsU2_cUbg', 'CYZ3phylT7Y', 'hkAFdIrTR00', 'VUNaND8fenw', 'hnfkZx4jmpA', 'GcImUUGmZ3I', '9DmxaUyjKTk'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utils_use_gpt4v import get_gpt4v_responses\n",
    "dirpath = 'result'\n",
    "response_dicts = get_gpt4v_responses(dirpath)\n",
    "print(response_dicts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VlLHMWFVgvk\n"
     ]
    }
   ],
   "source": [
    "# key = list(response_dicts.keys())[5]\n",
    "key = 'VlLHMWFVgvk'\n",
    "response_dict = response_dicts[key]\n",
    "print(key)\n",
    "# successes= response_dict['repeats']\n",
    "successes= response_dict['successes']\n",
    "success_0 = successes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"id\":\"chatcmpl-9AfE4PkTNn4pgEU9gECTHzv728ouY\",\"object\":\"chat.completion\",\"created\":1712328780,\"model\":\"gpt-4\",\"prompt_filter_results\":[{\"prompt_index\":0,\"content_filter_results\":{\"hate\":{\"filtered\":false,\"severity\":\"low\"},\"self_harm\":{\"filtered\":false,\"severity\":\"safe\"},\"sexual\":{\"filtered\":false,\"severity\":\"safe\"},\"violence\":{\"filtered\":false,\"severity\":\"safe\"}}}],\"choices\":[{\"finish_reason\":\"stop\",\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"{\\\\n\\\\\"00:00:00\\\\\": 0.0, \\\\n\\\\\"00:00:10.0080000\\\\\": 0.1, \\\\n\\\\\"00:00:15.0130000\\\\\": 0.3, \\\\n\\\\\"00:00:23.0190000\\\\\": 0.7, \\\\n\\\\\"00:00:27.0230000\\\\\": 0.5 \\\\n}\"},\"content_filter_results\":{\"hate\":{\"filtered\":false,\"severity\":\"safe\"},\"self_harm\":{\"filtered\":false,\"severity\":\"safe\"},\"sexual\":{\"filtered\":false,\"severity\":\"safe\"},\"violence\":{\"filtered\":false,\"severity\":\"safe\"}}}],\"usage\":{\"prompt_tokens\":1149,\"completion_tokens\":82,\"total_tokens\":1231}}'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "successes[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_1 = successes[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "for idx, success in enumerate(successes):\n",
    "\n",
    "    print(success.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"dataSources\": [{\"type\": \"AzureComputerVisionVideoIndex\", \"parameters\": {\"computerVisionBaseUrl\": \"https://vtomvisionwestus2.cognitiveservices.azure.com/computervision\", \"computerVisionApiKey\": \"d1838bf589f7415caf42195fea06b1b4\", \"indexName\": \"vtomvideoindex\", \"videoUrls\": [\"https://vtomstoragewest.blob.core.windows.net/videos/VlLHMWFVgvk.mp4?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-06-30T05%3A47%3A06Z&st=2024-03-04T22%3A47%3A06Z&spr=https&sig=jC486Giw%2FtQPoN%2F%2BwZAY4yQ7ZldNlZpKlok4iaYz3DA%3D\"], \"roleInformation\": \"You are an AI assistant that helps people find information related to videos and theory of mind.\"}}], \"enhancements\": {\"video\": {\"enabled\": true}}, \"messages\": [{\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": \"You are an AI assistant that helps people find information related to videos and theory of mind.\"}]}, {\"role\": \"user\", \"content\": [{\"type\": \"acv_document_id\", \"acv_document_id\": \"iVlLHMWFVgvk\"}, {\"type\": \"text\", \"text\": \"How relevant is each video frame to answering the question: \\\\\"How does the older woman feel when the woman in white starts throwing out her food?\\\\\"? Please output a dictionary of each video frame to its corresponding relevance score between 0.0 and 1.0 to the given question. For example: {\\\\\"00:00:06.0050000\\\\\": 0.0, \\\\\"00:00:15.0130000\\\\\": 0.02, \\\\\"00:00:16.0130000\\\\\": 0.03, \\\\\"00:00:17.0140000\\\\\": 0.08, \\\\\"00:00:18.0150000\\\\\": 0.07, \\\\\"00:00:19.0160000\\\\\": 0.02, \\\\\"00:00:20.0170000\\\\\": 0.03, \\\\\"00:00:22.0180000\\\\\": 0.05, \\\\\"00:00:24.0200000\\\\\": 0.09, \\\\\"00:00:30.0250000\\\\\": 0.10, \\\\\"00:00:31.0260000\\\\\": 0.99, \\\\\"00:00:37.0310000\\\\\": 0.81, \\\\\"00:00:38.0320000\\\\\": 0.77, \\\\\"00:00:39.0330000\\\\\": 0.75, \\\\\"00:00:40.0330000\\\\\": 0.79, \\\\\"00:00:41.0340000\\\\\": 0.65, \\\\\"00:00:43.0360000\\\\\": 0.62, \\\\\"00:00:48.0400000\\\\\": 0.22, \\\\\"00:00:49.0410000\\\\\": 0.09, \\\\\"00:00:50.0000000\\\\\": 0.11}\"}]}], \"temperature\": 0.7, \"top_p\": 0.95, \"max_tokens\": 800, \"stream\": false}'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "successes[1].request.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"id\":\"chatcmpl-9AfE4PkTNn4pgEU9gECTHzv728ouY\",\"object\":\"chat.completion\",\"created\":1712328780,\"model\":\"gpt-4\",\"prompt_filter_results\":[{\"prompt_index\":0,\"content_filter_results\":{\"hate\":{\"filtered\":false,\"severity\":\"low\"},\"self_harm\":{\"filtered\":false,\"severity\":\"safe\"},\"sexual\":{\"filtered\":false,\"severity\":\"safe\"},\"violence\":{\"filtered\":false,\"severity\":\"safe\"}}}],\"choices\":[{\"finish_reason\":\"stop\",\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"{\\\\n\\\\\"00:00:00\\\\\": 0.0, \\\\n\\\\\"00:00:10.0080000\\\\\": 0.1, \\\\n\\\\\"00:00:15.0130000\\\\\": 0.3, \\\\n\\\\\"00:00:23.0190000\\\\\": 0.7, \\\\n\\\\\"00:00:27.0230000\\\\\": 0.5 \\\\n}\"},\"content_filter_results\":{\"hate\":{\"filtered\":false,\"severity\":\"safe\"},\"self_harm\":{\"filtered\":false,\"severity\":\"safe\"},\"sexual\":{\"filtered\":false,\"severity\":\"safe\"},\"violence\":{\"filtered\":false,\"severity\":\"safe\"}}}],\"usage\":{\"prompt_tokens\":1149,\"completion_tokens\":82,\"total_tokens\":1231}}'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "successes[1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "How relevant is each video frame to answering the question: \"How does the older woman feel when the woman in white starts throwing out her food?\"? Please output a dictionary of each video frame to its corresponding relevance score between 0.0 and 1.0 to the given question. For example: {\"00:00:06.0050000\": 0.0, \"00:00:15.0130000\": 0.02, \"00:00:16.0130000\": 0.03, \"00:00:17.0140000\": 0.08, \"00:00:18.0150000\": 0.07, \"00:00:19.0160000\": 0.02, \"00:00:20.0170000\": 0.03, \"00:00:22.0180000\": 0.05, \"00:00:24.0200000\": 0.09, \"00:00:30.0250000\": 0.10, \"00:00:31.0260000\": 0.99, \"00:00:37.0310000\": 0.81, \"00:00:38.0320000\": 0.77, \"00:00:39.0330000\": 0.75, \"00:00:40.0330000\": 0.79, \"00:00:41.0340000\": 0.65, \"00:00:43.0360000\": 0.62, \"00:00:48.0400000\": 0.22, \"00:00:49.0410000\": 0.09, \"00:00:50.0000000\": 0.11}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'process_success_response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m question, frame_indices \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_success_response\u001b[49m(success_0)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'process_success_response' is not defined"
     ]
    }
   ],
   "source": [
    "question, frame_indices = process_success_response(success_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_0.request.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(success_0.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import get_cfg_defaults\n",
    "from azure_video_qa import AzureVideoQA\n",
    "cfg = get_cfg_defaults()\n",
    "cfg.freeze()\n",
    "# print(cfg)\n",
    "\n",
    "azure_qa = AzureVideoQA(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "from azure_video_qa import AzureVideoQA\n",
    "\n",
    "# client = AzureOpenAI(\n",
    "#     api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "#     api_version=\"2024-02-01\",\n",
    "#     azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "# )\n",
    "client = azure_qa.azure_openai_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import Stream\n",
    "\n",
    "cast_to = None  # httpx.Response\n",
    "client = None  # OpenAI\n",
    "response = success_0 # httpx.Response\n",
    "stream = Stream(cast_to=cast_to, response=response, client=client)\n",
    "# stream = Stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lol in stream:\n",
    "    print(lol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lol in success_0.iter_lines():\n",
    "    print(lol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in (success_0.raw.read_chunked()):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lol in success_0:\n",
    "    print(lol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_0.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "fromtimestamp = datetime.fromtimestamp\n",
    "\n",
    "\n",
    "def duration2length(str_duration: str) -> float:\n",
    "    '''\n",
    "    _summary_\n",
    "\n",
    "    Args:\n",
    "        str_duration (str): 00:00:00-00:00:55\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: _description_\n",
    "\n",
    "    Returns:\n",
    "        str: '0.00-60.019000'\n",
    "    '''\n",
    "    ts_start, ts_end = str_duration.split('-')\n",
    "    ts_start_dt = fromtimestamp(ts_start)\n",
    "    ts_end_dt = fromtimestamp(ts_end)\n",
    "    duration_dt = ts_end_dt - ts_start_dt\n",
    "    return duration_dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "\n",
    "# # datetime.fromtimestamp('00:00:55')\n",
    "# datetime.strptime('00:00:55', '%H:%M:%S').second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index2timestamp(frame_index: int, num_frames: int, timeframe_start_end: str) -> str:\n",
    "    '''\n",
    "    _summary_\n",
    "\n",
    "    Args:\n",
    "        frame_index (int): 16\n",
    "        num_frames (int): 100\n",
    "        timeframe_start_end (str): '0.00-60.019000'\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # timestamp2index('00:00:55', '0.00-60.019000', 100)\n",
    "# for timestamp in timestamps:\n",
    "#     print(timestamp, timestamp2index(timestamp, '0.00-60.019000', 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "value = timedelta(seconds=60.019000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeframe_duration = '0.00-60.019000'\n",
    "start_str, end_str = timeframe_duration.split('-')\n",
    "start_float, end_float = float(start_str), float(end_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The key is /Users/zhanwenchen/vtom/scripts/convert_instruction_json_to_training_format_tomloc.py:\n",
    "        # frame_idx_center = (content['frame_idx_end'] - content['frame_idx_start']) // 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "skipped = []\n",
    "for name, response_dict in tqdm(response_dicts.items()):\n",
    "    # pprint(process_video(response_dict))\n",
    "    try:\n",
    "        process_video(response_dict)\n",
    "    except:\n",
    "        print(f'skipped {name}')\n",
    "        skipped.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_video(response_dict_QqWrqHC8wjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from re import compile as re_compile\n",
    "\n",
    "# # timestamp_regex = r'^(([0-9]+:)?([0-5][0-9]:))?([0-5][0-9])$' # r'^(?:\\d+(?::[0-5][0-9]:[0-5][0-9])?|[0-5]?[0-9]:[0-5][0-9])$'\n",
    "# # timestamp_regex = r'^(?:\\d+(?::[0-5][0-9]:[0-5][0-9])?|[0-5]?[0-9]:[0-5][0-9])$'\n",
    "# timestamp_regex = r'^(?:\\d+(?::[0-5][0-9]:[0-5][0-9])?|[0-5]?[0-9]:[0-5][0-9])$'\n",
    "# # r'^[0-9]+:[0-5][0-9]:[0-5][0-9]$'\n",
    "\n",
    "# # Example usage:\n",
    "\n",
    "# timestamp = text_list_cleaned[1]['data']['choices'][0]['messages'][0]['delta']['content'] # '01:23:45'\n",
    "# # timestamp = '01:23:45'\n",
    "\n",
    "# timestamp_regex_compiled = re_compile(timestamp_regex)\n",
    "\n",
    "# # if re.match(timestamp_regex_compiled, timestamp):\n",
    "# # if lol:= timestamp_regex_compiled.match(timestamp):\n",
    "# if lol:= timestamp_regex_compiled.findall(timestamp):\n",
    "#   print(f'The timestamp is valid. lol={lol}')\n",
    "# else:\n",
    "#   print(f'The timestamp is invalid. lol={lol}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp_regex_compiled.match(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# # import ast\n",
    "# from json import loads as json_loads\n",
    "# from utils_use_gpt4v import response_text_to_list_dicts\n",
    "\n",
    "\n",
    "# # text_list_cleaned = [paragraph for paragraph in success_0.text.split(\n",
    "# #     '\\n') if paragraph.startswith('data:')]\n",
    "# # text_list_cleaned = [json_loads(f'{{{paragraph.replace('data:', '\"data\":')}}}') for paragraph in success_0.text.split(\n",
    "# # text_list_cleaned = [json_loads(f'{{{paragraph.replace('data:', '\"data\":')}}}') for paragraph in success_0.text.split(\n",
    "# #     '\\n') if paragraph.startswith('data:')]\n",
    "\n",
    "# # def response_text_to_list_dicts(response_text: str) -> list[dict]:\n",
    "# #     text_list_cleaned = []\n",
    "# #     for paragraph in response_text.split('\\n'):\n",
    "# #         if paragraph.startswith('data:'):\n",
    "# #             string = f'{{{paragraph.replace('data:', '\"data\":').replace('[DONE]', '\"[DONE]\"')}}}'\n",
    "# #             try:\n",
    "# #                 cleaned_paragraph = json_loads(string)\n",
    "# #             except:\n",
    "# #                 print(string)\n",
    "# #             text_list_cleaned.append(cleaned_paragraph)\n",
    "# text_list_cleaned = response_text_to_list_dicts(success_0.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import ast\n",
    "# doubled_quoted = '{' + text_list_cleaned[0] + '}'\n",
    "# doubled_quoted = doubled_quoted.replace('{data:', '{\"data\":')\n",
    "# json.loads(doubled_quoted)\n",
    "\n",
    "# # ast.literal_eval(doubled_quoted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_loads(f'{{{text_list_cleaned[0].replace('data:', '\"data\":')}}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ('{' + success_0.text + '}').json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_0.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_dict_list_to_tuple(dicty):\n",
    "#     return {k: tuple(v) for k, v in dicty.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_dict_equality(dict1, dict2):\n",
    "#     # converted_existing = convert_dict_list_to_tuple(existing_video_dict)\n",
    "#     # converted_new = convert_dict_list_to_tuple(result_dict_video)\n",
    "#     assert hash(tuple(dict1)) == hash(tuple(dict2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dicts = []\n",
    "# for response_dict in response_dicts:\n",
    "#     if not 'successes' in response_dict:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the same key, a list of candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "\n",
    "# # final_dict = {}\n",
    "# final_dict = defaultdict(list)\n",
    "\n",
    "# for video_id, response_dict in response_dicts.items():\n",
    "#     if 'successes' in response_dict:\n",
    "#         # then it's a single video\n",
    "#         pass\n",
    "#     else:\n",
    "#         for video_id, result_dict_video in response_dict.items():\n",
    "#             final_dict[video_id].append(result_dict_video)\n",
    "#             # if video_id in final_dict:\n",
    "#             #     existing_video_dict = final_dict[video_id]\n",
    "#             #     print(existing_video_dict)\n",
    "#             #     final_dict[video_id]\n",
    "#             #     # converted_existing = convert_dict_list_to_tuple(existing_video_dict)\n",
    "#             #     # converted_new = convert_dict_list_to_tuple(result_dict_video)\n",
    "#             #     assert hash(tuple(existing_video_dict)) == hash(tuple(result_dict_video))\n",
    "#             # else:\n",
    "#             #     final_dict[video_id] = result_dict_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pickle import dump as pickle_dump\n",
    "# with open('final_dict.pkl', 'wb') as f:\n",
    "#     pickle_dump(final_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from json import loads as json_loads\n",
    "# from pprint import pprint\n",
    "\n",
    "\n",
    "# for response in existing_video_dict:\n",
    "#     request_dict = json_loads(response.request.body)\n",
    "#     # print(request_dict['messages'][1])\n",
    "#     print(request_dict['messages'][1]['content'][0]['acv_document_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from json import loads as json_loads\n",
    "# from pprint import pprint\n",
    "\n",
    "\n",
    "# for response in result_dict_video:\n",
    "#     request_dict = json_loads(response.request.body)\n",
    "#     # print(request_dict['messages'][1])\n",
    "#     print(request_dict['messages'][1]['content'][0]['acv_document_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol = response_dicts.sort(key=len)\n",
    "largest = len(response_dicts[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest = response_dicts[-2]\n",
    "largest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "response_dict = response_dicts[0]\n",
    "pprint(response_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pickle import dump as pickle_dump\n",
    "# largest = response_dicts[-1]\n",
    "# for video_id, dict_current_video in largest.items():\n",
    "#   with open(f'./result/{video_id}.pkl', 'wb') as f:\n",
    "#       pickle_dump(dict_current_video, f)\n",
    "\n",
    "# with open(f'./largest.pkl', 'wb') as f:\n",
    "#     pickle_dump(largest, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failures = response_dict['failures']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_failure_overlap(result_dict: dict):\n",
    "    '''\n",
    "    Check to see if there are any failures in the response_dicts and if they are covered by the successes (same question)\n",
    "\n",
    "    Args:\n",
    "        result_dict (dict): _description_\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    '''\n",
    "\n",
    "    failures = result_dict['failures']\n",
    "    successes = result_dict['successes']\n",
    "    questions_failures = {}\n",
    "    # for response_dict in response_dicts:\n",
    "    #     if len(response_dict['choices']) > 1:\n",
    "    #         print(response_dict)\n",
    "    #         break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vtom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
